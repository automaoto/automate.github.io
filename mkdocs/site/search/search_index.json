{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MAOTO API Docs \ud83d\ude80","text":"<p>This documentation provides an overview of the <code>maoto-agent</code> package.</p>"},{"location":"#sections","title":"Sections:","text":"<ul> <li>Installation Guide: How to install and use <code>maoto-agent</code>.</li> <li>API Reference: Full documentation for <code>maoto-agent</code>.</li> <li>Examples: Sample implementations.</li> </ul>"},{"location":"examples/","title":"Sample Usage","text":""},{"location":"reference/maoto_agent/","title":"Maoto Agent API","text":""},{"location":"reference/maoto_agent/#maoto_agent","title":"<code>maoto_agent</code>","text":""},{"location":"reference/maoto_agent/#maoto_agent.Maoto","title":"<code>Maoto</code>","text":"Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>class Maoto:\n    class EventDrivenQueueProcessor:\n        def __init__(self, logger, worker_count=10, min_workers=1, max_workers=20, scale_threshold=5, scale_down_delay=30, outer_class=None):\n            self.outer_class = outer_class\n            self.task_queue = queue.Queue()\n            self.initial_worker_count = worker_count\n            self.max_workers = max_workers\n            self.min_workers = min_workers\n            self.scale_threshold = scale_threshold\n            self.workers = []\n            self.stop_event = threading.Event()\n            self.producer_thread = None\n            self.monitor_thread = None\n            self.completed_tasks = 0\n            self.error_count = 0\n            self.lock = threading.Lock()\n            self.last_scale_down_time = 0\n            self.scale_down_delay = scale_down_delay  # Minimum time (seconds) between scale-downs\n            self.logger = logger\n\n            atexit.register(self.cleanup)\n\n        def start_workers(self, worker_func, count):\n            for _ in range(count):\n                worker = threading.Thread(target=self.worker_process, args=(worker_func,))\n                worker.daemon = True\n                worker.start()\n                self.workers.append(worker)\n\n        def start_producer(self, producer_func):\n            self.producer_thread = threading.Thread(target=self.run_producer, args=(producer_func,))\n            self.producer_thread.daemon = True\n            self.producer_thread.start()\n\n        def stop_extra_workers(self, count):\n            for _ in range(count):\n                self.task_queue.put(None)  # Insert None as a poison pill to terminate one worker\n\n        def cleanup(self):\n            \"\"\"Cleanup function to ensure graceful termination.\"\"\"\n            self.logger.info(\"Cleaning up...\")\n\n            self.stop_event.set()\n\n            # Wait for the producer thread to finish\n            if self.producer_thread:\n                self.producer_thread.join()\n\n            # Insert poison pills to stop worker threads\n            for _ in range(len(self.workers)):\n                self.task_queue.put(None)\n\n            # Wait for all worker threads to finish\n            for worker in self.workers:\n                worker.join()\n\n            # Wait for the monitor thread to finish\n            if self.monitor_thread:\n                self.monitor_thread.join()\n\n            if self.outer_class:\n                if self.outer_class._at_shutdown:\n                    asyncio.run(self.outer_class._at_shutdown())\n\n            self.logger.info(\"All processes have been terminated gracefully.\")\n\n        def run_producer(self, producer_func):\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            try:\n                loop.run_until_complete(producer_func(self.task_queue, self.stop_event))\n            except Exception as e:\n                self.logger.error(f\"Producer encountered an exception: {e}\")\n            finally:\n                loop.close()\n\n        def worker_process(self, worker_func):\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            async def process_tasks():\n                while not self.stop_event.is_set() or not self.task_queue.empty():\n                    try:\n                        task = self.task_queue.get(timeout=1)\n                        if task is None:  # Poison pill received\n                            self.task_queue.task_done()\n                            break\n                        await worker_func(task)\n                        self.task_queue.task_done()\n                        with self.lock:\n                            self.completed_tasks += 1\n                    except queue.Empty:\n                        continue\n                    except Exception as e:\n                        with self.lock:\n                            self.error_count += 1\n                        self.logger.error(f\"Worker encountered an exception: {e}\")\n\n            try:\n                loop.run_until_complete(process_tasks())\n            finally:\n                # Remove the current worker from the workers list on termination\n                with self.lock:\n                    self.workers.remove(threading.current_thread())\n                loop.close()\n\n        def signal_handler(self, signum, frame):\n            self.logger.info(\"Termination signal received\")\n\n            self.cleanup()\n\n            # After handling the signal, forward it to the main program\n            self.logger.info(f\"Forwarding signal {signum} to the main process.\")\n            signal.signal(signum, signal.SIG_DFL)  # Reset the signal handler to default\n            os.kill(os.getpid(), signum)  # Re-raise the signal to propagate it\n\n        def monitor_system(self, worker_func):\n            while not self.stop_event.is_set():\n                with self.lock:\n                    queue_size = self.task_queue.qsize()\n                    current_worker_count = len(self.workers)\n\n                # Scale up workers if the queue size exceeds the threshold and we haven't reached max_workers\n                if queue_size &gt; self.scale_threshold and current_worker_count &lt; self.max_workers:\n                    self.logger.info(f\"Scaling up: Adding workers (Current: {current_worker_count})\")\n                    additional_workers = max(min(int((((max(queue_size - self.scale_threshold, 0)) * 0.2) ** 1.3)), self.max_workers - current_worker_count), 0)\n                    self.start_workers(worker_func, additional_workers)\n\n                # Scale down if the queue is well below the threshold, we have more workers than min_workers,\n                # and it's been long enough since the last scale down\n                elif queue_size &lt; self.scale_threshold / 2 and current_worker_count &gt; self.min_workers:\n                    current_time = time.time()\n                    if current_time - self.last_scale_down_time &gt; self.scale_down_delay:\n                        self.logger.debug(f\"Scaling down: Removing workers (Current: {current_worker_count})\")\n                        self.stop_extra_workers(1)\n                        self.last_scale_down_time = current_time  # Update the last scale-down time\n\n                # Log system status\n                self.logger.debug(\n                    f\"Queue size: {queue_size}, Active workers: {current_worker_count}, \"\n                    f\"Completed tasks: {self.completed_tasks}, Errors: {self.error_count}\"\n                )\n                self.completed_tasks = 0\n\n                # Monitor system resources\n                cpu_usage = psutil.cpu_percent(interval=1)\n                memory_usage = psutil.virtual_memory().percent\n                self.logger.debug(f\"System CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%\")\n\n                # Sleep before the next monitoring check\n                time.sleep(5)\n\n        def run(self, producer_func, worker_func):\n            # Clear the stop event in case it's set from a previous run\n            self.stop_event.clear()\n\n            signal.signal(signal.SIGINT, self.signal_handler)\n            signal.signal(signal.SIGTERM, self.signal_handler)\n\n            if self.outer_class:\n                if self.outer_class._at_startup:\n                    asyncio.run(self.outer_class._at_startup())\n\n\n            self.start_workers(worker_func, self.initial_worker_count)\n            self.start_producer(lambda task_queue, stop_event: producer_func(task_queue, stop_event))\n\n            self.monitor_thread = threading.Thread(target=self.monitor_system, args=(worker_func,))\n            self.monitor_thread.daemon = True\n            self.monitor_thread.start()\n\n    class ServerMode:\n        class AuthDirective(SchemaDirectiveVisitor):\n            def visit_field_definition(self, field: FieldDefinitionNode, _) -&gt; FieldDefinitionNode:\n                original_resolver = field.resolve\n\n                def resolve_auth(root, info, **kwargs):\n                    request = info.context[\"request\"]\n\n                    # TODO: do something meaningful here (the following does not always work)\n                    # Extract the request headers from context\n                    # try:\n                    #     address = request.headers.get(\"Origin\", \"\")\n                    #     if address not in [\"https://api.maoto.world\", \"http://localhost\"]:\n                    #         raise GraphQLError(f\"Unauthorized: Request not from allowed domain {address}.\")\n\n                    # except Exception as e:\n                    #     raise GraphQLError(f\"Authorization failed: {str(e)}\")\n\n                    # Proceed to the original resolver if authentication passes\n                    return original_resolver(root, info, **kwargs)\n\n                field.resolve = resolve_auth\n                return field\n\n        def __init__(self, logger, outer_class=None):\n            self.logger = logger\n            self.outer_class = outer_class\n\n            # Resolver functions\n            self.query = QueryType()\n            self.mutation = MutationType()\n            self.subscription = SubscriptionType()\n\n            self.datetime_scalar = ScalarType(\"Datetime\")\n            @self.datetime_scalar.serializer\n            def serialize_datetime(value: datetime) -&gt; str:\n                return value.isoformat()\n            @self.datetime_scalar.value_parser\n            def parse_datetime_value(value: str) -&gt; datetime:\n                return parser.parse(value)\n\n            self.json_scalar = ScalarType(\"JSON\")\n            @self.json_scalar.serializer\n            def serialize_json(value: dict) -&gt; str:\n                return json.dumps(value)\n            @self.json_scalar.value_parser\n            def parse_json_value(value: str) -&gt; dict:\n                return json.loads(value)\n\n            @self.mutation.field(\"forwardActioncalls\")\n            async def forward_actioncalls(_, info, actioncalls: list[dict[str, object]]) -&gt; list[bool]:\n                actioncalls = [Actioncall(\n                    actioncall_id=uuid.UUID(actioncall[\"actioncall_id\"]),\n                    apikey_id=uuid.UUID(actioncall[\"apikey_id\"]),\n                    time=datetime.fromisoformat(actioncall[\"time\"]),\n                    action_id=uuid.UUID(actioncall[\"action_id\"]),\n                    post_id=uuid.UUID(actioncall[\"post_id\"]),\n                    parameters=actioncall[\"parameters\"],\n                ) for actioncall in actioncalls]\n\n                status = []\n                for actioncall in actioncalls:\n                    try:\n                        #await self.outer_class._resolve_event(actioncall)\n                        asyncio.create_task(self.outer_class._resolve_event(actioncall))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving actioncall.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardResponses\")\n            async def forward_responses(_, info, responses: list[dict[str, object]]) -&gt; list[bool]:\n                responses = [Response(\n                    response_id=uuid.UUID(response[\"response_id\"]),\n                    post_id=uuid.UUID(response[\"post_id\"]),\n                    description=response[\"description\"],\n                    apikey_id=uuid.UUID(response[\"apikey_id\"]),\n                    time=datetime.fromisoformat(response[\"time\"]),\n                ) for response in responses]\n\n                status = []\n                for response in responses:\n                    try:\n                        #await self.outer_class._resolve_event(response)\n                        asyncio.create_task(self.outer_class._resolve_event(response))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving response.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardBidRequests\")\n            async def forward_bidrequests(_, info, bidrequests: list[dict[str, object]]) -&gt; list[bool]:\n                bidrequests = [BidRequest(\n                    action_id=bidrequest[\"action_id\"],\n                    post=Post(\n                        post_id=uuid.UUID(bidrequest[\"post\"][\"post_id\"]),\n                        description=bidrequest[\"post\"][\"description\"],\n                        context=bidrequest[\"post\"][\"context\"],\n                        apikey_id=uuid.UUID(bidrequest[\"post\"][\"apikey_id\"]),\n                        time=datetime.fromisoformat(bidrequest[\"post\"][\"time\"]),\n                        resolved=bidrequest[\"post\"][\"resolved\"],\n                    )\n                ) for bidrequest in bidrequests]\n\n                status = []\n                for bidrequest in bidrequests:\n                    try:\n                        #await self.outer_class._resolve_event(bidrequest)\n                        asyncio.create_task(self.outer_class._resolve_event(bidrequest))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving bid request.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardPAPaymentRequests\")\n            async def forward_paymentrequests(_, info, pa_paymentrequests: list[dict[str, object]]) -&gt; list[bool]:\n                paymentrequests = [PAPaymentRequest(\n                    ui_id=pa_paymentrequest[\"ui_id\"],\n                    payment_link=pa_paymentrequest[\"payment_link\"],\n                ) for pa_paymentrequest in pa_paymentrequests]\n\n                status = []\n                for paymentrequest in paymentrequests:\n                    try:\n                        #await self.outer_class._resolve_event(paymentrequest)\n                        asyncio.create_task(self.outer_class._resolve_event(paymentrequest))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving payment request.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardPALocationResponses\")\n            async def forward_locationresponses(_, info, pa_locationresponses: list[dict[str, object]]) -&gt; list[bool]:\n                locationresponses = [PALocationResponse(\n                    ui_id=pa_locationresponse[\"ui_id\"],\n                    location=Location(\n                        latitude=pa_locationresponse[\"location\"][\"latitude\"],\n                        longitude=pa_locationresponse[\"location\"][\"longitude\"],\n                    )\n                ) for pa_locationresponse in pa_locationresponses]\n\n                status = []\n                for locationresponse in locationresponses:\n                    try:\n                        #await self.outer_class._resolve_event(locationresponse)\n                        asyncio.create_task(self.outer_class._resolve_event(locationresponse))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving location response.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardPALocationRequests\")\n            async def forward_locationrequests(_, info, pa_locationrequests: list[dict[str, object]]) -&gt; list[bool]:\n                locationrequests = [PALocationRequest(\n                    ui_id=pa_locationrequest[\"ui_id\"],\n                ) for pa_locationrequest in pa_locationrequests]\n\n                status = []\n                for locationrequest in locationrequests:\n                    try:\n                        #await self.outer_class._resolve_event(locationrequest)\n                        asyncio.create_task(self.outer_class._resolve_event(locationrequest))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving location request.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardPAUserMessages\")\n            async def forward_usermessages(_, info, pa_usermessages: list[dict[str, object]]) -&gt; list[bool]:\n                usermessages = [PAUserMessage(\n                    ui_id=pa_usermessage[\"ui_id\"],\n                    text=pa_usermessage[\"text\"],\n                ) for pa_usermessage in pa_usermessages]\n\n                status = []\n                for usermessage in usermessages:\n                    try:\n                        #await self.outer_class._resolve_event(usermessage)\n                        asyncio.create_task(self.outer_class._resolve_event(usermessage))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving user message.\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardPAUserResponses\")\n            async def forward_userresponses(_, info, pa_userresponses: list[dict[str, object]]) -&gt; list[bool]:\n                userresponses = [PAUserResponse(\n                    ui_id=pa_userresponse[\"ui_id\"],\n                    text=pa_userresponse[\"text\"],\n                ) for pa_userresponse in pa_userresponses]\n\n                status = []\n                for userresponse in userresponses:\n                    try:\n                        #await self.outer_class._resolve_event(userresponse)\n                        asyncio.create_task(self.outer_class._resolve_event(userresponse))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving user response: {e}\")\n                        status.append(False)\n\n                return status\n\n            @self.mutation.field(\"forwardPANewConversations\")\n            async def forward_newconversations(_, info, pa_newconversations: list[dict[str, object]]) -&gt; list[bool]:\n                newconversations = [PANewConversation(\n                    ui_id=pa_newconversation[\"ui_id\"],\n                ) for pa_newconversation in pa_newconversations]\n\n                status = []\n                for newconversation in newconversations:\n                    try:\n                        #await self.outer_class._resolve_event(newconversation)\n                        asyncio.create_task(self.outer_class._resolve_event(newconversation))\n\n                        status.append(True)\n                    except Exception as e:\n                        self.logger.error(f\"Error resolving new conversation.\")\n                        status.append(False)\n\n                return status\n\n            self.authdirective = self.AuthDirective\n\n            # Create the executable schema\n            self.schema = make_executable_schema(self.outer_class._schema, self.query, self.mutation, self.datetime_scalar, self.json_scalar, directives={\"auth\": self.authdirective})\n\n            self.graphql_app = GraphQL(\n                self.schema, \n                debug=True,\n            )\n\n            async def health_check(request):\n                return JSONResponse({\"status\": \"ok\"})\n\n            self.routes=[\n                Route(\"/graphql\", self.graphql_app.handle_request, methods=[\"GET\", \"POST\", \"OPTIONS\"]),\n                Route(\"/healthz\", health_check, methods=[\"GET\"]),\n            ]\n\n            self.middleware = [\n                Middleware(\n                    TrustedHostMiddleware,\n                    allowed_hosts=['maoto.world', '*.maoto.world', 'localhost', '*.svc.cluster.local', '*.amazonaws.com', '*.ngrok.app', '*.ngrok-free.app']\n                ),\n                # TODO: HTTPS not working yet: incompatible versions?\n                # https://chatgpt.com/c/c50f8b80-05be-4f39-a4de-540725536ed3\n                # Middleware(HTTPSRedirectMiddleware)\n            ]\n\n        def custom_format_error(error, debug=False):\n            logging.exception(error)\n\n            return {\"message\": \"An unexpected error occurred, please contact support.\"}\n\n        def start_server(self):\n            self.app = Starlette(\n                routes=self.routes,\n                middleware=self.middleware,\n                on_startup=[self.startup],\n                on_shutdown=[self.shutdown]\n            )\n            return self.app\n\n        async def startup(self):\n            \"\"\"\n            Actions to perform on application startup.\n            \"\"\"\n\n            if self.outer_class:\n                if self.outer_class._at_startup:\n                    await self.outer_class._at_startup()\n\n        async def shutdown(self):\n            \"\"\"\n            Actions to perform on application shutdown.\n            \"\"\"\n\n            if self.outer_class:\n                if self.outer_class._at_shutdown:\n                    await self.outer_class._at_shutdown()\n\n    class GraphQLService:\n        def __init__(self, outer_class, apikey_value: str):\n            self._outer_class = outer_class\n            self._apikey_value = apikey_value\n\n        def _get_client(self, server_url: str) -&gt; Client:\n            transport = AIOHTTPTransport(\n                url=server_url,\n                headers={\"Authorization\": self._apikey_value, \"Version\": get_distribution(\"maoto_agent\").version},\n            )\n            client = Client(\n                transport=transport,\n                fetch_schema_from_transport=False,  # Schema is already provided\n                schema=self._outer_class._schema,  # Use the preloaded schema\n            )\n            return client\n\n        async def send_to_other_server(self, objects: list[object], server_url: str):         \n            results = []\n            for obj in objects:\n                # get key from obj\n                key = self._outer_class._map_obj_to_handler_in_registry[type(obj)]\n                match key:\n                    case \"Actioncall\":\n                        value_name = \"actioncalls\"\n                        query = gql_client('''\n                            mutation forwardActioncalls($actioncalls: [Actioncall!]!) {\n                                forwardActioncalls(actioncalls: $actioncalls)\n                            }\n                        ''')\n                    case \"Response\":\n                        value_name = \"responses\"\n                        query = gql_client('''\n                            mutation forwardResponses($responses: [Response!]!) {\n                                forwardResponses(responses: $responses)\n                            }\n                        ''')\n                    case \"BidRequest\":\n                        value_name = \"bidrequests\"\n                        query = gql_client('''\n                            mutation forwardBidRequests($bidrequests: [BidRequest!]!) {\n                                forwardBidRequests(bidrequests: $bidrequests)\n                            }\n                        ''')\n                    case \"PaymentRequest\":\n                        value_name = \"paymentrequests\"\n                        query = gql_client('''\n                            mutation forwardPaymentRequests($paymentrequests: [PaymentRequest!]!) {\n                                forwardPaymentRequests(paymentrequests: $paymentrequests)\n                            }\n                        ''')\n                    case \"PALocationRequest\":\n                        value_name = \"pa_locationrequests\"\n                        query = gql_client('''\n                            mutation forwardPALocationRequests($pa_locationrequests: [PALocationRequest!]!) {\n                                forwardPALocationRequests(pa_locationrequests: $pa_locationrequests)\n                            }\n                        ''')\n                    case \"PALocationResponse\":\n                        value_name = \"pa_locationresponses\"\n                        query = gql_client('''\n                            mutation forwardPALocationResponses($pa_locationresponses: [PALocationResponse!]!) {\n                                forwardPALocationResponses(pa_locationresponses: $pa_locationresponses)\n                            }\n                        ''')\n                    case \"PAUserMessage\":\n                        value_name = \"pa_usermessages\"\n                        query = gql_client('''\n                            mutation forwardPAUserMessages($pa_usermessages: [PAUserMessage!]!) {\n                                forwardPAUserMessages(pa_usermessages: $pa_usermessages)\n                            }\n                        ''')\n                    case \"PAUserResponse\":\n                        value_name = \"pa_userresponses\"\n                        query = gql_client('''\n                            mutation forwardPAUserResponses($pa_userresponses: [PAUserResponse!]!) {\n                                forwardPAUserResponses(pa_userresponses: $pa_userresponses)\n                            }\n                        ''')\n                    case \"PAPaymentRequest\":\n                        value_name = \"pa_paymentrequests\"\n                        query = gql_client('''\n                            mutation forwardPAPaymentRequests($pa_paymentrequests: [PAPaymentRequest!]!) {\n                                forwardPAPaymentRequests(pa_paymentrequests: $pa_paymentrequests)\n                            }\n                        ''')\n                    case \"PANewConversation\":\n                        value_name = \"pa_newconversations\"\n                        query = gql_client('''\n                            mutation forwardPANewConversations($pa_newconversations: [PANewConversation!]!) {\n                                forwardPANewConversations(pa_newconversations: $pa_newconversations)\n                            }\n                        ''')\n                    case _:  # Fallback\n                        raise ValueError(f\"Invalid key: {key}\")\n\n                graphql_client = self._get_client(server_url)\n                self._outer_class.logger.info(f\"Sending to server: {obj}\")\n                result = await graphql_client.execute_async(query, variable_values={value_name: [obj.to_dict()]})\n                self._outer_class.logger.info(f\"Return value: {result}\")\n                results.append(result)\n\n            return results\n\n    def __init__(self, logging_level=None, connection_mode: str = \"nat\", db_connection=False):\n        # Set up logging and debug mode\n        self._debug = os.getenv(\"DEBUG\", \"False\").lower() == \"true\"\n        # Set up logging\n        self._logging_level = logging_level if logging_level else logging.DEBUG if self._debug else logging.INFO\n        logging.basicConfig(level=self._logging_level, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n        self.logger = logging.getLogger(__name__)\n        # Disable INFO logs for gql and websockets\n        logging.getLogger(\"gql\").setLevel(logging.DEBUG if self._debug else logging.WARNING)\n        logging.getLogger(\"websockets\").setLevel(logging.DEBUG if self._debug else logging.WARNING)\n\n        self._db_connection = db_connection\n        self._db_connection_pool = None\n        if self._db_connection:\n            # Environment variables for database connection\n            self._db_hostname = os.getenv(\"POSTGRES_HOST\")\n            self._db_name = os.getenv(\"POSTGRES_DB\")\n            self._db_username = os.getenv(\"POSTGRES_USER\")\n            self._db_user_password = os.getenv(\"POSTGRES_PASSWORD\")\n            self._db_port = os.getenv(\"POSTGRES_PORT\")\n\n            # Validate that all required env variables are set\n            if not all([self._db_hostname, self._db_name, self._db_username, self._db_user_password, self._db_port]):\n                raise EnvironmentError(\n                    \"POSTGRES_HOST, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD, and POSTGRES_PORT must be set\"\n                )\n\n            # Construct the PostgreSQL connection URL\n            self._database_url = (\n                f\"postgresql+asyncpg://{self._db_username}:{self._db_user_password}\"\n                f\"@{self._db_hostname}:{self._db_port}/{self._db_name}\"\n            )\n\n            # Create a connection pool\n            self._db_connection_pool = databases.Database(self._database_url)\n\n        self._schema = gql_server(\"\"\"\n            directive @auth on FIELD_DEFINITION\n\n            scalar Datetime\n            scalar JSON\n\n            input Actioncall {\n                actioncall_id: ID\n                action_id: ID\n                post_id: ID\n                apikey_id: ID\n                parameters: JSON\n                time: Datetime\n            }\n\n            input Response {\n                response_id: ID\n                post_id: ID\n                description: String\n                apikey_id: ID\n                time: Datetime\n            }\n\n            input Post {\n                post_id: ID!\n                description: String!\n                context: String!\n                apikey_id: ID!\n                time: Datetime!\n                resolved: Boolean!\n            }\n\n            input BidRequest {\n                action_id: ID\n                post: Post\n            }\n\n            input PaymentRequest {\n                actioncall_id: ID\n                post_id: ID\n                payment_link: String\n            }\n\n            input Location {\n                latitude: Float\n                longitude: Float\n            }\n\n            input PALocationRequest {\n                ui_id: String\n            }\n\n            input PALocationResponse {\n                ui_id: String\n                location: Location\n            }\n\n            input PAUserMessage {\n                ui_id: String\n                text: String\n            }\n\n            input PAUserResponse {\n                ui_id: String\n                text: String\n            }\n\n            input PAPaymentRequest {\n                ui_id: String\n                payment_link: String\n            }\n\n            input PANewConversation {\n                ui_id: String\n            }\n\n            type Query {\n                _dummy: String\n            }\n\n            type Mutation {\n                forwardActioncalls(actioncalls: [Actioncall!]!): [Boolean!]! @auth\n                forwardResponses(responses: [Response!]!): [Boolean!]! @auth\n                forwardBidRequests(bidrequests: [BidRequest!]!): [Boolean!]! @auth\n                forwardPaymentRequests(paymentrequests: [PaymentRequest!]!): [Boolean!]! @auth\n\n                forwardPALocationResponses(pa_locationresponses: [PALocationResponse!]!): [Boolean!]! @auth\n                forwardPALocationRequests(pa_locationrequests: [PALocationRequest!]!): [Boolean!]! @auth\n                forwardPAUserMessages(pa_usermessages: [PAUserMessage!]!): [Boolean!]! @auth\n                forwardPAUserResponses(pa_userresponses: [PAUserResponse!]!): [Boolean!]! @auth\n                forwardPAPaymentRequests(pa_paymentrequests: [PAPaymentRequest!]!): [Boolean!]! @auth\n                forwardPANewConversations(pa_newconversations: [PANewConversation!]!): [Boolean!]! @auth           \n            }\n            \"\"\")\n\n        self.domain_mp = os.environ.get(\"DOMAIN_MP\", \"mp.maoto.world\")\n        self.domain_pa = os.environ.get(\"DOMAIN_PA\", \"pa.maoto.world\")\n\n        self.protocol = os.environ.get(\"SERVER_PROTOCOL\", \"http\")\n        self.server_port = os.environ.get(\"SERVER_PORT\") if os.environ.get(\"SERVER_PORT\") else \"4000\"\n\n        self._url_mp = self.protocol + \"://\" + self.domain_mp + \":\" + self.server_port + \"/graphql\"\n        self._url_pa = self.protocol + \"://\" + self.domain_pa + \":\" + self.server_port + \"/graphql\"\n\n        self._url_marketplace_subscription = self._url_mp.replace(self.protocol, \"ws\")\n\n        self._apikey_value = os.environ.get(\"MAOTO_API_KEY\")\n        if self._apikey_value in [None, \"\"]:\n            raise ValueError(\"API key is required. (Set MAOTO_API_KEY environment variable)\")\n\n        # CLient for ui and personal assistant to send messages to personal assistant and ui\n        self._graphql_service = self.GraphQLService(self, self._apikey_value)\n\n        self._action_cache = []\n        self._id_action_map = {}\n\n        self._map_obj_to_handler_in_registry = {\n            Response: \"Response\",\n            Actioncall: \"Actioncall\",\n            BidRequest: \"BidRequest\",\n            PaymentRequest: \"PaymentRequest\",\n\n            PAPaymentRequest: \"PAPaymentRequest\",\n            PALocationRequest: \"PALocationRequest\",\n            PAUserMessage: \"PAUserMessage\",\n\n            PALocationResponse: \"PALocationResponse\",\n            PAUserResponse: \"PAUserResponse\",\n            PANewConversation: \"PANewConversation\",\n        }\n\n        self._handler_registry = {\n            \"CustomStartup\": None,\n            \"CustomShutdown\": None,\n\n            \"Response\": None,\n            \"Actioncall\": {},\n            \"Actioncall_fallback\": None,\n            \"PaymentRequest\": None,\n            \"BidRequest\": {},\n            \"BidRequest_fallback\": None,\n\n            \"PAPaymentRequest\": None,\n            \"PALocationResponse\": None,\n            \"PALocationRequest\": None,\n            \"PAUserMessage\": None,\n            \"PAUserResponse\": None,\n            \"PANewConversation\": None,\n        }\n\n        self._connection_mode = connection_mode\n        if self._connection_mode not in [\"marketplace\", \"no_nat\", \"nat\", \"closed\"]:\n            raise ValueError(\"Invalid connection mode.\")\n\n        # to send messages to personal assistant and ui\n        if self._connection_mode == \"marketplace\":\n            if self._connection_mode != \"marketplace\":\n                transport = AIOHTTPTransport(\n                    url=self._url_mp,\n                    headers={\"Authorization\": self._apikey_value},\n                )\n                self.client = Client(transport=transport, fetch_schema_from_transport=True)\n\n        if self._connection_mode == \"nat\":\n            self.server = self.EventDrivenQueueProcessor(self.logger, worker_count=1, scale_threshold=10, outer_class=self)\n        if self._connection_mode == \"no_nat\":\n            self.server = self.ServerMode(self.logger, self)\n\n    def start_server(self, blocking=False) -&gt; Starlette | None:\n        if self._connection_mode == \"closed\":\n            raise self.logger.warning(\"Cannot start server when mode is set offline.\")\n\n        elif self._connection_mode == \"nat\":\n            self.server.run(self._subscribe_to_events, self._resolve_event)\n\n            if blocking:\n                def handler(signum, frame):\n                    self.logger.info(\"Stopped by Ctrl+C\")\n                    sys.exit(0)\n\n                # Assign the SIGINT (Ctrl+C) signal to the handler\n                signal.signal(signal.SIGINT, handler)\n\n                self.logger.info(\"Running... Press Ctrl+C to stop.\")\n                signal.pause()  # Blocks here until a signal (Ctrl+C) is received\n\n            return None\n        elif self._connection_mode == \"no_nat\":\n            return self.server.start_server()\n        else:\n            raise ValueError(\"Invalid connection mode.\")\n\n    async def _at_startup(self):\n        if self._db_connection:\n            await self._startup_db_conn_pool()\n\n        if self._handler_registry[\"CustomStartup\"]:\n            await self._handler_registry[\"CustomStartup\"]()\n\n    async def _at_shutdown(self):\n        if self._db_connection:\n            await self._shutdown_db_conn_pool()\n\n        if self._handler_registry[\"CustomShutdown\"]:\n            await self._handler_registry[\"CustomShutdown\"]()\n\n    async def _startup_db_conn_pool(self):\n        \"\"\"Establish a database connection with automatic reconnection.\"\"\"\n        retries = 5\n        while retries:\n            try:\n                await self._db_connection_pool.connect()\n                self.logger.info(\"Connected to the database!\")\n                break\n            except asyncpg.exceptions.ConnectionDoesNotExistError:\n                self.logger.warning(f\"Database connection failed. Retrying in 5 seconds... ({retries} attempts left)\")\n                retries -= 1\n                await asyncio.sleep(5)\n\n        if not retries:\n            raise RuntimeError(\"Failed to establish a database connection after multiple attempts.\")\n\n    async def _shutdown_db_conn_pool(self):\n        \"\"\"Disconnect from the database.\"\"\"\n        if self._db_connection_pool:\n            await self._db_connection_pool.disconnect()\n            self.logger.info(\"Disconnected from the database.\")\n\n    async def fetch_all(self, query, values=None):\n        \"\"\"Fetch multiple records from the database.\"\"\"\n        try:\n            return await self._db_connection_pool.fetch_all(query=query, values=values)\n        except asyncpg.exceptions.PostgresError as e:\n            self.logger.error(\"Database error: %s\", e)\n            raise GraphQLError(\"Database error occurred.\")\n\n    async def execute(self, query, values=None):\n        \"\"\"Execute an INSERT, UPDATE, or DELETE statement.\"\"\"\n        try:\n            return await self._db_connection_pool.execute(query=query, values=values)\n        except asyncpg.exceptions.PostgresError as e:\n            self.logger.error(\"Database execution error: %s\", e)\n            raise GraphQLError(\"Database execution error.\")\n\n    @asynccontextmanager\n    async def transaction(self):\n        \"\"\"\n        Return an async context manager so that\n        `async with agent.transaction(): ...` works.\n        \"\"\"\n        async with self._db_connection_pool.transaction():\n            # You can do any setup here if needed\n            yield\n            # teardown or exception handling automatically\n\n    # Decorator to allow synchronous and asynchronous usage of the same method\n    @staticmethod\n    def _sync_or_async(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Check if there's an active event loop\n                loop = asyncio.get_running_loop()\n                # If we're inside an active loop, just return the coroutine\n                return func(*args, **kwargs)\n            except RuntimeError:\n                # If no loop is running, create a new one\n                return asyncio.run(func(*args, **kwargs))\n        return wrapper\n\n    @_sync_or_async\n    async def check_status(self) -&gt; bool:\n        query = gql_client('''\n        query {\n            checkStatus\n        }\n        ''')\n        result = await self.client.execute_async(query)\n        return result[\"checkStatus\"]\n\n    async def _create_actions_core(self, new_actions: list[NewAction]) -&gt; list[Action]: # TODO: confirm this the first time when agent is started as well (not only when reconnecting)\n        if new_actions:\n            actions = [{'name': action.get_name(), 'parameters': action.get_parameters(), 'description': action.get_description(), 'tags': action.get_tags(), 'cost': action.get_cost(), 'followup': action.get_followup()} for action in new_actions]\n            query = gql_client('''\n            mutation createActions($new_actions: [NewAction!]!) {\n                createActions(new_actions: $new_actions) {\n                    action_id\n                    apikey_id\n                    name\n                    parameters\n                    description\n                    tags\n                    cost\n                    followup\n                    time\n                }\n            }\n            ''')\n\n            result = await self.client.execute_async(query, variable_values={\"new_actions\": actions})\n            data_list = result[\"createActions\"]\n            self._id_action_map.update({data[\"action_id\"]: data[\"name\"] for data in data_list})\n\n            actions = [Action(\n                action_id=uuid.UUID(data[\"action_id\"]),\n                apikey_id=uuid.UUID(data[\"apikey_id\"]),\n                name=data[\"name\"],\n                parameters=data[\"parameters\"],\n                description=data[\"description\"],\n                tags=data[\"tags\"],\n                cost=data[\"cost\"],\n                followup=data[\"followup\"],\n                time=datetime.fromisoformat(data[\"time\"])\n            ) for data in data_list]\n        else:\n            actions = []\n\n        return actions\n\n    @_sync_or_async\n    async def create_actions(self, new_actions: list[NewAction]) -&gt; list[Action]:\n        self._action_cache.extend(new_actions)\n\n        actions = await self._create_actions_core(new_actions)\n\n        return actions\n\n    @_sync_or_async\n    async def delete_actions(self, action_ids: list[Action | str]) -&gt; list[bool]: #TODO: this should not actually delete but deactivate only\n        action_ids = [str(action.get_action_id()) if isinstance(action, Action) else str(action) for action in action_ids]\n        query = gql_client('''\n        mutation deleteActions($action_ids: [ID!]!) {\n            deleteActions(action_ids: $action_ids)\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"action_ids\": action_ids})\n\n        # remove the respecitive actions from the cache\n        self._action_cache = [action for action in self._action_cache if action.get_action_id() not in action_ids]\n\n        return result[\"deleteActions\"]\n\n    @_sync_or_async\n    async def get_actions(self, apikey_ids: list[ApiKey | str]) -&gt; list[Action]:\n        apikey_ids = [str(apikey.get_apikey_id()) if isinstance(apikey, ApiKey) else str(apikey) for apikey in apikey_ids]\n        query = gql_client('''\n        query getActions($apikey_ids: [ID!]!) {\n            getActions(apikey_ids: $apikey_ids) {\n                action_id\n                apikey_id\n                name\n                parameters\n                description\n                tags\n                cost\n                followup\n                time\n            }\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"apikey_ids\": apikey_ids})\n        data_list = result[\"getActions\"]\n        return [Action(\n            action_id=uuid.UUID(data[\"action_id\"]),\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            name=data[\"name\"],\n            parameters=data[\"parameters\"],\n            description=data[\"description\"],\n            tags=data[\"tags\"],\n            cost=data[\"cost\"],\n            followup=data[\"followup\"],\n            time=datetime.fromisoformat(data[\"time\"])\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def get_own_actions(self) -&gt; list[Action]:\n        query = gql_client('''\n        query {\n            getOwnActions {\n                action_id\n                apikey_id\n                name\n                parameters\n                description\n                tags\n                cost\n                followup\n                time\n            }\n        }\n        ''')\n\n        result = await self.client.execute_async(query)\n        data_list = result[\"getOwnActions\"]\n        return [Action(\n            action_id=uuid.UUID(data[\"action_id\"]),\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            name=data[\"name\"],\n            parameters=data[\"parameters\"],\n            description=data[\"description\"],\n            tags=data[\"tags\"],\n            cost=data[\"cost\"],\n            followup=data[\"followup\"],\n            time=datetime.fromisoformat(data[\"time\"])\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def fetch_action_info(self, new_posts: list[NewPost]) -&gt; list[str]:\n        posts = [{'description': post.get_description(), 'context': post.get_context()} for post in new_posts]\n        query = gql_client('''\n        query fetchActionInfo($new_posts: [NewPost!]!) {\n            fetchActionInfo(new_posts: $new_posts)\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"new_posts\": posts})\n        return result[\"fetchActionInfo\"]\n\n    @_sync_or_async\n    async def create_posts(self, new_posts: list[NewPost]) -&gt; list[Post]:\n        posts = [{'description': post.get_description(), 'context': post.get_context()} for post in new_posts]\n        query = gql_client('''\n        mutation createPosts($new_posts: [NewPost!]!) {\n            createPosts(new_posts: $new_posts) {\n                post_id\n                description\n                context\n                apikey_id\n                time\n                resolved\n            }\n        }\n        ''')\n\n        try:\n            result = await self.client.execute_async(query, variable_values={\"new_posts\": posts})\n        except Exception as e:\n            self.logger.error(f\"Error creating posts: {e}\")\n            GraphQLError(f\"Error creating posts: {e}\")\n\n        data_list = result[\"createPosts\"]\n        return [Post(\n            post_id=uuid.UUID(data[\"post_id\"]),\n            description=data[\"description\"],\n            context=data[\"context\"],\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            time=datetime.fromisoformat(data[\"time\"]),\n            resolved=data[\"resolved\"]\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def delete_posts(self, post_ids: list[Post | str]) -&gt; list[bool]: # TODO: only make this deactivate instead of delete (mark as done)\n        post_ids = [str(post.get_post_id()) if isinstance(post, Post) else str(post) for post in post_ids]\n        query = gql_client('''\n        mutation deletePosts($post_ids: [ID!]!) {\n            deletePosts(post_ids: $post_ids)\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"post_ids\": post_ids})\n        return result[\"deletePosts\"]\n\n    @_sync_or_async\n    async def get_posts(self, apikey_ids: list[ApiKey | str]) -&gt; list[Post]:\n        apikey_ids = [str(apikey.get_apikey_id()) if isinstance(apikey, ApiKey) else str(apikey) for apikey in apikey_ids]\n        query = gql_client('''\n        query getPosts($apikey_ids: [ID!]!) {\n            getPosts(apikey_ids: $apikey_ids) {\n                post_id\n                description\n                context\n                apikey_id\n                time\n                resolved\n            }\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"apikey_ids\": apikey_ids})\n        data_list = result[\"getPosts\"]\n        return [Post(\n            post_id=uuid.UUID(data[\"post_id\"]),\n            description=data[\"description\"],\n            context=data[\"context\"],\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            time=datetime.fromisoformat(data[\"time\"]),\n            resolved=data[\"resolved\"]\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def get_own_posts(self) -&gt; list[Post]:\n        query = gql_client('''\n        query {\n            getOwnPosts {\n                post_id\n                description\n                context\n                apikey_id\n                time\n                resolved\n            }\n        }\n        ''')\n\n        result = await self.client.execute_async(query)\n        data_list = result[\"getOwnPosts\"]\n        return [Post(\n            post_id=uuid.UUID(data[\"post_id\"]),\n            description=data[\"description\"],\n            context=data[\"context\"],\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            time=datetime.fromisoformat(data[\"time\"]),\n            resolved=data[\"resolved\"]\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def create_actioncalls(self, new_actioncalls: list[NewActioncall]) -&gt; list[Actioncall]:\n        actioncalls = [{'action_id': str(actioncall.action_id), 'post_id': str(actioncall.post_id), 'parameters': actioncall.parameters} for actioncall in new_actioncalls]\n        query = gql_client('''\n        mutation createActioncalls($new_actioncalls: [NewActioncall!]!) {\n            createActioncalls(new_actioncalls: $new_actioncalls) {\n                actioncall_id\n                action_id\n                post_id\n                apikey_id\n                parameters\n                time\n            }\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"new_actioncalls\": actioncalls})\n        data_list = result[\"createActioncalls\"]\n        return [Actioncall(\n            actioncall_id=uuid.UUID(data[\"actioncall_id\"]),\n            action_id=uuid.UUID(data[\"action_id\"]),\n            post_id=uuid.UUID(data[\"post_id\"]),\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            parameters=data[\"parameters\"],\n            time=datetime.fromisoformat(data[\"time\"])\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def create_responses(self, new_responses: list[NewResponse]) -&gt; list[Response]:\n        responses = [{'post_id': str(response.post_id), 'description': response.description} for response in new_responses]\n        query = gql_client('''\n        mutation createResponses($new_responses: [NewResponse!]!) {\n            createResponses(new_responses: $new_responses) {\n                response_id\n                post_id\n                description\n                apikey_id\n                time\n            }\n        }\n        ''')\n\n        result = await self.client.execute_async(query, variable_values={\"new_responses\": responses})\n        data_list = result[\"createResponses\"]\n        return [Response(\n            response_id=uuid.UUID(data[\"response_id\"]),\n            post_id=uuid.UUID(data[\"post_id\"]),\n            description=data[\"description\"],\n            apikey_id=uuid.UUID(data[\"apikey_id\"]),\n            time=datetime.fromisoformat(data[\"time\"])\n        ) for data in data_list]\n\n    @_sync_or_async\n    async def create_bidresponses(self, bidresponses: list[BidResponse]) -&gt; list[bool]:\n        # Prepare the input\n        bidresponses = [\n            {\n                'action_id': str(bidresponse.get_action_id()),\n                'post_id': str(bidresponse.get_post_id()),\n                'cost': bidresponse.get_cost()\n            }\n            for bidresponse in bidresponses\n        ]\n\n        # Define the GQL mutation\n        query = gql_client('''\n        mutation createBidResponses($bidresponses: [BidResponse!]!) {\n            createBidResponses(bidresponses: $bidresponses)\n        }\n        ''')\n\n        # Execute asynchronously\n        data_list = await self.client.execute_async(\n            query,\n            variable_values={\"bidresponses\": bidresponses}\n        )\n\n        # 'createBidResponses' is already a list of booleans, so just return it.\n        return data_list['createBidResponses']\n\n    # only used for open connection server\n    async def _subscribe_to_events(self, task_queue, stop_event):\n        # Subscription to listen for both actioncalls and responses using __typename\n        subscription = gql_client('''\n        subscription subscribeToEvents {\n            subscribeToEvents {\n                __typename\n                ... on Actioncall {\n                    actioncall_id\n                    action_id\n                    post_id\n                    apikey_id\n                    parameters\n                    time\n                }\n                ... on Response {\n                    response_id\n                    post_id\n                    description\n                    apikey_id\n                    time\n                }\n                ... on BidRequest {\n                    action_id\n                    post {\n                        post_id\n                        description\n                        context\n                        apikey_id\n                        time\n                        resolved\n                    }\n                }\n                ... on PaymentRequest {\n                    actioncall_id\n                    post_id\n                    payment_link\n                }\n                ... on PALocationResponse {\n                    ui_id\n                    location {\n                        latitude\n                        longitude\n                    }\n                }             \n                ... on PAPaymentRequest {\n                    ui_id\n                    payment_link\n                }\n                ... on PALocationRequest {\n                    ui_id\n                }\n                ... on PAUserMessage {\n                    ui_id\n                    text\n                }\n                ... on PAUserResponse {\n                    ui_id\n                    text\n                }\n                ... on PANewConversation {\n                    ui_id\n                }\n            }\n        }\n        ''')\n\n        # A helper to stop the subscription task when stop_event is triggered\n        async def monitor_stop_event(subscription_task):\n            while not stop_event.is_set():\n                await asyncio.sleep(1)\n            subscription_task.cancel()\n\n        # Create a task to monitor for stop_event in parallel\n        subscription_task = asyncio.create_task(\n            self._run_subscription_with_reconnect(task_queue, subscription, stop_event)\n        )\n        stop_monitoring_task = asyncio.create_task(\n            monitor_stop_event(subscription_task)\n        )\n\n        try:\n            await subscription_task\n        except asyncio.CancelledError:\n            self.logger.info(\"Subscription was cancelled\")\n        except Exception as e:\n            self.logger.error(f\"An unexpected error occurred: {e}\")\n        finally:\n            stop_monitoring_task.cancel()\n\n    async def _run_subscription_with_reconnect(self, task_queue, subscription, stop_event):\n        \"\"\"\n        This method continuously attempts to subscribe. If the subscription breaks,\n        it retries (unless stop_event is set), using randomized exponential backoff.\n        \"\"\"\n        base_delay = 6  # Initial delay in seconds\n        max_delay = 60  # Max delay before retrying\n        attempt = 0     # Track the number of consecutive failures\n        reconnect = False\n\n        while not stop_event.is_set():\n            try:\n\n                # Create transport for each attempt\n                transport = WebsocketsTransport(\n                    url=self._url_marketplace_subscription,\n                    headers={\"Authorization\": self._apikey_value},\n                )\n\n                # Open a session and subscribe\n                async with Client(\n                    transport=transport,\n                    fetch_schema_from_transport=True\n                ) as session:\n                    self.logger.info(\"Successfully connected. Listening for events.\")\n                    attempt = 0  # Reset attempt count on successful connection\n\n                    if reconnect:\n                        try:\n                            actions = await self._create_actions_core(self._action_cache)\n                            self.logger.info(f\"Successfully recreated {len(actions)} actions.\")\n                        except Exception as e:\n                            self.logger.info(f\"Error recreating actions.\")\n\n                    reconnect = True # Set reconnect flag to True if reconnected\n\n                    async for result in session.subscribe(subscription):\n                        # Process the subscription event\n                        await self._handle_subscription_event(task_queue, result)\n\n            except asyncio.CancelledError:\n                self.logger.warning(\"Subscription task cancelled. This error is only shown when the task is cancelled inproperly.\")\n                break\n            except Exception as e:\n                self.logger.warning(f\"Subscription interrupted. Will attempt to reconnect.\")\n\n            # Calculate exponential backoff with jitter\n            if not stop_event.is_set():\n                delay = min(base_delay * (2 ** attempt), max_delay)  # Exponential growth\n                jitter = random.uniform(0.5, 1.5)  # Random jitter multiplier (\u00b150%)\n                delay *= jitter  # Apply jitter\n\n                self.logger.info(f\"Retrying in {delay:.2f} seconds...\")\n                await asyncio.sleep(delay)\n                attempt += 1  # Increase attempt count for next retry\n\n        self.logger.info(\"Stopped subscription due to stop_event or cancellation.\")\n\n    async def _handle_subscription_event(self, task_queue, result):\n        \"\"\"\n        Handle the result of the subscription. Identify the\n        event type via __typename, instantiate the corresponding\n        event object, and put it on the queue.\n        \"\"\"\n        event_data = result['subscribeToEvents']\n        event_type = event_data[\"__typename\"]\n\n        if event_type == \"Actioncall\":\n            event = Actioncall( #  TODO: make these class inits use class methods (from dict?)\n                actioncall_id=uuid.UUID(event_data[\"actioncall_id\"]),\n                action_id=uuid.UUID(event_data[\"action_id\"]),\n                post_id=uuid.UUID(event_data[\"post_id\"]),\n                apikey_id=uuid.UUID(event_data[\"apikey_id\"]),\n                parameters=event_data[\"parameters\"],\n                time=datetime.fromisoformat(event_data[\"time\"])\n            )\n        elif event_type == \"Response\":\n            event = Response(\n                response_id=uuid.UUID(event_data[\"response_id\"]),\n                post_id=uuid.UUID(event_data[\"post_id\"]),\n                description=event_data[\"description\"],\n                apikey_id=uuid.UUID(event_data[\"apikey_id\"]) if event_data[\"apikey_id\"] else None,\n                time=datetime.fromisoformat(event_data[\"time\"])\n            )\n        elif event_type == \"BidRequest\":\n            post_data = event_data[\"post\"]\n            post = Post(\n                post_id=uuid.UUID(post_data[\"post_id\"]),\n                description=post_data[\"description\"],\n                context=post_data[\"context\"],\n                apikey_id=uuid.UUID(post_data[\"apikey_id\"]),\n                time=datetime.fromisoformat(post_data[\"time\"]),\n                resolved=post_data[\"resolved\"]\n            )\n            event = BidRequest(\n                action_id=uuid.UUID(event_data[\"action_id\"]),\n                post=post\n            )\n        elif event_type == \"PaymentRequest\":\n            event = PaymentRequest(\n                actioncall_id=uuid.UUID(event_data[\"actioncall_id\"]),\n                post_id=uuid.UUID(event_data[\"post_id\"]),\n                payment_link=event_data[\"payment_link\"]\n            )\n        else:\n            self.logger.error(f\"Unknown event type: {event_type}\")\n            return\n\n        # Put the event on the queue for handling in your system\n        task_queue.put(event)\n\n    def register_handler(self, event_type: str, name: str | None = None):\n        def decorator(func):\n            # python case (new version) statement here\n            if name is not None:\n                self._handler_registry[event_type][name] = func\n            else:\n                self._handler_registry[event_type] = func\n            return func\n        return decorator\n\n    async def _resolve_event(self, obj: object):\n        # get handler registry key for the object\n        handler_registry_key = self._map_obj_to_handler_in_registry[type(obj)]\n\n        # get handler from registry\n        try:\n            if handler_registry_key in [\"Actioncall\", \"BidRequest\"]:\n                try:\n                    handler = self._handler_registry[handler_registry_key][self._id_action_map[str(obj.get_action_id())]]\n                except KeyError:\n                    handler = self._handler_registry[f\"{handler_registry_key}_fallback\"]\n\n                if handler_registry_key == \"Actioncall\":\n                    response_description = await handler(obj.get_apikey_id(), obj.get_parameters())\n                    new_response = NewResponse(\n                        post_id=obj.get_post_id(),\n                        description=response_description\n                    )\n                    await self.create_responses([new_response])\n\n                elif handler_registry_key == \"BidRequest\":\n                    bid_value = await handler(obj.get_post())\n                    new_bid = BidResponse(\n                        action_id=obj.get_action_id(),\n                        post_id=obj.get_post().get_post_id(),\n                        cost=bid_value\n                    )\n                    await self.create_bidresponses([new_bid])\n\n            else:\n                handler = self._handler_registry[handler_registry_key]\n        except KeyError:\n            self.logger.error(f\"No handler found for {handler_registry_key}\")\n            return\n\n        # call handler\n        await handler(obj)\n\n    async def send_to_assistant(self, objects: list[object]):\n        await self._graphql_service.send_to_other_server(objects, self._url_pa)\n\n    async def send_to_ui(self, objects: list[object], ui_url: str):\n        await self._graphql_service.send_to_other_server(objects, ui_url)\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.EventDrivenQueueProcessor","title":"<code>EventDrivenQueueProcessor</code>","text":"Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>class EventDrivenQueueProcessor:\n    def __init__(self, logger, worker_count=10, min_workers=1, max_workers=20, scale_threshold=5, scale_down_delay=30, outer_class=None):\n        self.outer_class = outer_class\n        self.task_queue = queue.Queue()\n        self.initial_worker_count = worker_count\n        self.max_workers = max_workers\n        self.min_workers = min_workers\n        self.scale_threshold = scale_threshold\n        self.workers = []\n        self.stop_event = threading.Event()\n        self.producer_thread = None\n        self.monitor_thread = None\n        self.completed_tasks = 0\n        self.error_count = 0\n        self.lock = threading.Lock()\n        self.last_scale_down_time = 0\n        self.scale_down_delay = scale_down_delay  # Minimum time (seconds) between scale-downs\n        self.logger = logger\n\n        atexit.register(self.cleanup)\n\n    def start_workers(self, worker_func, count):\n        for _ in range(count):\n            worker = threading.Thread(target=self.worker_process, args=(worker_func,))\n            worker.daemon = True\n            worker.start()\n            self.workers.append(worker)\n\n    def start_producer(self, producer_func):\n        self.producer_thread = threading.Thread(target=self.run_producer, args=(producer_func,))\n        self.producer_thread.daemon = True\n        self.producer_thread.start()\n\n    def stop_extra_workers(self, count):\n        for _ in range(count):\n            self.task_queue.put(None)  # Insert None as a poison pill to terminate one worker\n\n    def cleanup(self):\n        \"\"\"Cleanup function to ensure graceful termination.\"\"\"\n        self.logger.info(\"Cleaning up...\")\n\n        self.stop_event.set()\n\n        # Wait for the producer thread to finish\n        if self.producer_thread:\n            self.producer_thread.join()\n\n        # Insert poison pills to stop worker threads\n        for _ in range(len(self.workers)):\n            self.task_queue.put(None)\n\n        # Wait for all worker threads to finish\n        for worker in self.workers:\n            worker.join()\n\n        # Wait for the monitor thread to finish\n        if self.monitor_thread:\n            self.monitor_thread.join()\n\n        if self.outer_class:\n            if self.outer_class._at_shutdown:\n                asyncio.run(self.outer_class._at_shutdown())\n\n        self.logger.info(\"All processes have been terminated gracefully.\")\n\n    def run_producer(self, producer_func):\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        try:\n            loop.run_until_complete(producer_func(self.task_queue, self.stop_event))\n        except Exception as e:\n            self.logger.error(f\"Producer encountered an exception: {e}\")\n        finally:\n            loop.close()\n\n    def worker_process(self, worker_func):\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def process_tasks():\n            while not self.stop_event.is_set() or not self.task_queue.empty():\n                try:\n                    task = self.task_queue.get(timeout=1)\n                    if task is None:  # Poison pill received\n                        self.task_queue.task_done()\n                        break\n                    await worker_func(task)\n                    self.task_queue.task_done()\n                    with self.lock:\n                        self.completed_tasks += 1\n                except queue.Empty:\n                    continue\n                except Exception as e:\n                    with self.lock:\n                        self.error_count += 1\n                    self.logger.error(f\"Worker encountered an exception: {e}\")\n\n        try:\n            loop.run_until_complete(process_tasks())\n        finally:\n            # Remove the current worker from the workers list on termination\n            with self.lock:\n                self.workers.remove(threading.current_thread())\n            loop.close()\n\n    def signal_handler(self, signum, frame):\n        self.logger.info(\"Termination signal received\")\n\n        self.cleanup()\n\n        # After handling the signal, forward it to the main program\n        self.logger.info(f\"Forwarding signal {signum} to the main process.\")\n        signal.signal(signum, signal.SIG_DFL)  # Reset the signal handler to default\n        os.kill(os.getpid(), signum)  # Re-raise the signal to propagate it\n\n    def monitor_system(self, worker_func):\n        while not self.stop_event.is_set():\n            with self.lock:\n                queue_size = self.task_queue.qsize()\n                current_worker_count = len(self.workers)\n\n            # Scale up workers if the queue size exceeds the threshold and we haven't reached max_workers\n            if queue_size &gt; self.scale_threshold and current_worker_count &lt; self.max_workers:\n                self.logger.info(f\"Scaling up: Adding workers (Current: {current_worker_count})\")\n                additional_workers = max(min(int((((max(queue_size - self.scale_threshold, 0)) * 0.2) ** 1.3)), self.max_workers - current_worker_count), 0)\n                self.start_workers(worker_func, additional_workers)\n\n            # Scale down if the queue is well below the threshold, we have more workers than min_workers,\n            # and it's been long enough since the last scale down\n            elif queue_size &lt; self.scale_threshold / 2 and current_worker_count &gt; self.min_workers:\n                current_time = time.time()\n                if current_time - self.last_scale_down_time &gt; self.scale_down_delay:\n                    self.logger.debug(f\"Scaling down: Removing workers (Current: {current_worker_count})\")\n                    self.stop_extra_workers(1)\n                    self.last_scale_down_time = current_time  # Update the last scale-down time\n\n            # Log system status\n            self.logger.debug(\n                f\"Queue size: {queue_size}, Active workers: {current_worker_count}, \"\n                f\"Completed tasks: {self.completed_tasks}, Errors: {self.error_count}\"\n            )\n            self.completed_tasks = 0\n\n            # Monitor system resources\n            cpu_usage = psutil.cpu_percent(interval=1)\n            memory_usage = psutil.virtual_memory().percent\n            self.logger.debug(f\"System CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%\")\n\n            # Sleep before the next monitoring check\n            time.sleep(5)\n\n    def run(self, producer_func, worker_func):\n        # Clear the stop event in case it's set from a previous run\n        self.stop_event.clear()\n\n        signal.signal(signal.SIGINT, self.signal_handler)\n        signal.signal(signal.SIGTERM, self.signal_handler)\n\n        if self.outer_class:\n            if self.outer_class._at_startup:\n                asyncio.run(self.outer_class._at_startup())\n\n\n        self.start_workers(worker_func, self.initial_worker_count)\n        self.start_producer(lambda task_queue, stop_event: producer_func(task_queue, stop_event))\n\n        self.monitor_thread = threading.Thread(target=self.monitor_system, args=(worker_func,))\n        self.monitor_thread.daemon = True\n        self.monitor_thread.start()\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.EventDrivenQueueProcessor.cleanup","title":"<code>cleanup()</code>","text":"<p>Cleanup function to ensure graceful termination.</p> Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>def cleanup(self):\n    \"\"\"Cleanup function to ensure graceful termination.\"\"\"\n    self.logger.info(\"Cleaning up...\")\n\n    self.stop_event.set()\n\n    # Wait for the producer thread to finish\n    if self.producer_thread:\n        self.producer_thread.join()\n\n    # Insert poison pills to stop worker threads\n    for _ in range(len(self.workers)):\n        self.task_queue.put(None)\n\n    # Wait for all worker threads to finish\n    for worker in self.workers:\n        worker.join()\n\n    # Wait for the monitor thread to finish\n    if self.monitor_thread:\n        self.monitor_thread.join()\n\n    if self.outer_class:\n        if self.outer_class._at_shutdown:\n            asyncio.run(self.outer_class._at_shutdown())\n\n    self.logger.info(\"All processes have been terminated gracefully.\")\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.ServerMode","title":"<code>ServerMode</code>","text":"Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>class ServerMode:\n    class AuthDirective(SchemaDirectiveVisitor):\n        def visit_field_definition(self, field: FieldDefinitionNode, _) -&gt; FieldDefinitionNode:\n            original_resolver = field.resolve\n\n            def resolve_auth(root, info, **kwargs):\n                request = info.context[\"request\"]\n\n                # TODO: do something meaningful here (the following does not always work)\n                # Extract the request headers from context\n                # try:\n                #     address = request.headers.get(\"Origin\", \"\")\n                #     if address not in [\"https://api.maoto.world\", \"http://localhost\"]:\n                #         raise GraphQLError(f\"Unauthorized: Request not from allowed domain {address}.\")\n\n                # except Exception as e:\n                #     raise GraphQLError(f\"Authorization failed: {str(e)}\")\n\n                # Proceed to the original resolver if authentication passes\n                return original_resolver(root, info, **kwargs)\n\n            field.resolve = resolve_auth\n            return field\n\n    def __init__(self, logger, outer_class=None):\n        self.logger = logger\n        self.outer_class = outer_class\n\n        # Resolver functions\n        self.query = QueryType()\n        self.mutation = MutationType()\n        self.subscription = SubscriptionType()\n\n        self.datetime_scalar = ScalarType(\"Datetime\")\n        @self.datetime_scalar.serializer\n        def serialize_datetime(value: datetime) -&gt; str:\n            return value.isoformat()\n        @self.datetime_scalar.value_parser\n        def parse_datetime_value(value: str) -&gt; datetime:\n            return parser.parse(value)\n\n        self.json_scalar = ScalarType(\"JSON\")\n        @self.json_scalar.serializer\n        def serialize_json(value: dict) -&gt; str:\n            return json.dumps(value)\n        @self.json_scalar.value_parser\n        def parse_json_value(value: str) -&gt; dict:\n            return json.loads(value)\n\n        @self.mutation.field(\"forwardActioncalls\")\n        async def forward_actioncalls(_, info, actioncalls: list[dict[str, object]]) -&gt; list[bool]:\n            actioncalls = [Actioncall(\n                actioncall_id=uuid.UUID(actioncall[\"actioncall_id\"]),\n                apikey_id=uuid.UUID(actioncall[\"apikey_id\"]),\n                time=datetime.fromisoformat(actioncall[\"time\"]),\n                action_id=uuid.UUID(actioncall[\"action_id\"]),\n                post_id=uuid.UUID(actioncall[\"post_id\"]),\n                parameters=actioncall[\"parameters\"],\n            ) for actioncall in actioncalls]\n\n            status = []\n            for actioncall in actioncalls:\n                try:\n                    #await self.outer_class._resolve_event(actioncall)\n                    asyncio.create_task(self.outer_class._resolve_event(actioncall))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving actioncall.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardResponses\")\n        async def forward_responses(_, info, responses: list[dict[str, object]]) -&gt; list[bool]:\n            responses = [Response(\n                response_id=uuid.UUID(response[\"response_id\"]),\n                post_id=uuid.UUID(response[\"post_id\"]),\n                description=response[\"description\"],\n                apikey_id=uuid.UUID(response[\"apikey_id\"]),\n                time=datetime.fromisoformat(response[\"time\"]),\n            ) for response in responses]\n\n            status = []\n            for response in responses:\n                try:\n                    #await self.outer_class._resolve_event(response)\n                    asyncio.create_task(self.outer_class._resolve_event(response))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving response.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardBidRequests\")\n        async def forward_bidrequests(_, info, bidrequests: list[dict[str, object]]) -&gt; list[bool]:\n            bidrequests = [BidRequest(\n                action_id=bidrequest[\"action_id\"],\n                post=Post(\n                    post_id=uuid.UUID(bidrequest[\"post\"][\"post_id\"]),\n                    description=bidrequest[\"post\"][\"description\"],\n                    context=bidrequest[\"post\"][\"context\"],\n                    apikey_id=uuid.UUID(bidrequest[\"post\"][\"apikey_id\"]),\n                    time=datetime.fromisoformat(bidrequest[\"post\"][\"time\"]),\n                    resolved=bidrequest[\"post\"][\"resolved\"],\n                )\n            ) for bidrequest in bidrequests]\n\n            status = []\n            for bidrequest in bidrequests:\n                try:\n                    #await self.outer_class._resolve_event(bidrequest)\n                    asyncio.create_task(self.outer_class._resolve_event(bidrequest))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving bid request.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardPAPaymentRequests\")\n        async def forward_paymentrequests(_, info, pa_paymentrequests: list[dict[str, object]]) -&gt; list[bool]:\n            paymentrequests = [PAPaymentRequest(\n                ui_id=pa_paymentrequest[\"ui_id\"],\n                payment_link=pa_paymentrequest[\"payment_link\"],\n            ) for pa_paymentrequest in pa_paymentrequests]\n\n            status = []\n            for paymentrequest in paymentrequests:\n                try:\n                    #await self.outer_class._resolve_event(paymentrequest)\n                    asyncio.create_task(self.outer_class._resolve_event(paymentrequest))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving payment request.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardPALocationResponses\")\n        async def forward_locationresponses(_, info, pa_locationresponses: list[dict[str, object]]) -&gt; list[bool]:\n            locationresponses = [PALocationResponse(\n                ui_id=pa_locationresponse[\"ui_id\"],\n                location=Location(\n                    latitude=pa_locationresponse[\"location\"][\"latitude\"],\n                    longitude=pa_locationresponse[\"location\"][\"longitude\"],\n                )\n            ) for pa_locationresponse in pa_locationresponses]\n\n            status = []\n            for locationresponse in locationresponses:\n                try:\n                    #await self.outer_class._resolve_event(locationresponse)\n                    asyncio.create_task(self.outer_class._resolve_event(locationresponse))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving location response.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardPALocationRequests\")\n        async def forward_locationrequests(_, info, pa_locationrequests: list[dict[str, object]]) -&gt; list[bool]:\n            locationrequests = [PALocationRequest(\n                ui_id=pa_locationrequest[\"ui_id\"],\n            ) for pa_locationrequest in pa_locationrequests]\n\n            status = []\n            for locationrequest in locationrequests:\n                try:\n                    #await self.outer_class._resolve_event(locationrequest)\n                    asyncio.create_task(self.outer_class._resolve_event(locationrequest))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving location request.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardPAUserMessages\")\n        async def forward_usermessages(_, info, pa_usermessages: list[dict[str, object]]) -&gt; list[bool]:\n            usermessages = [PAUserMessage(\n                ui_id=pa_usermessage[\"ui_id\"],\n                text=pa_usermessage[\"text\"],\n            ) for pa_usermessage in pa_usermessages]\n\n            status = []\n            for usermessage in usermessages:\n                try:\n                    #await self.outer_class._resolve_event(usermessage)\n                    asyncio.create_task(self.outer_class._resolve_event(usermessage))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving user message.\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardPAUserResponses\")\n        async def forward_userresponses(_, info, pa_userresponses: list[dict[str, object]]) -&gt; list[bool]:\n            userresponses = [PAUserResponse(\n                ui_id=pa_userresponse[\"ui_id\"],\n                text=pa_userresponse[\"text\"],\n            ) for pa_userresponse in pa_userresponses]\n\n            status = []\n            for userresponse in userresponses:\n                try:\n                    #await self.outer_class._resolve_event(userresponse)\n                    asyncio.create_task(self.outer_class._resolve_event(userresponse))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving user response: {e}\")\n                    status.append(False)\n\n            return status\n\n        @self.mutation.field(\"forwardPANewConversations\")\n        async def forward_newconversations(_, info, pa_newconversations: list[dict[str, object]]) -&gt; list[bool]:\n            newconversations = [PANewConversation(\n                ui_id=pa_newconversation[\"ui_id\"],\n            ) for pa_newconversation in pa_newconversations]\n\n            status = []\n            for newconversation in newconversations:\n                try:\n                    #await self.outer_class._resolve_event(newconversation)\n                    asyncio.create_task(self.outer_class._resolve_event(newconversation))\n\n                    status.append(True)\n                except Exception as e:\n                    self.logger.error(f\"Error resolving new conversation.\")\n                    status.append(False)\n\n            return status\n\n        self.authdirective = self.AuthDirective\n\n        # Create the executable schema\n        self.schema = make_executable_schema(self.outer_class._schema, self.query, self.mutation, self.datetime_scalar, self.json_scalar, directives={\"auth\": self.authdirective})\n\n        self.graphql_app = GraphQL(\n            self.schema, \n            debug=True,\n        )\n\n        async def health_check(request):\n            return JSONResponse({\"status\": \"ok\"})\n\n        self.routes=[\n            Route(\"/graphql\", self.graphql_app.handle_request, methods=[\"GET\", \"POST\", \"OPTIONS\"]),\n            Route(\"/healthz\", health_check, methods=[\"GET\"]),\n        ]\n\n        self.middleware = [\n            Middleware(\n                TrustedHostMiddleware,\n                allowed_hosts=['maoto.world', '*.maoto.world', 'localhost', '*.svc.cluster.local', '*.amazonaws.com', '*.ngrok.app', '*.ngrok-free.app']\n            ),\n            # TODO: HTTPS not working yet: incompatible versions?\n            # https://chatgpt.com/c/c50f8b80-05be-4f39-a4de-540725536ed3\n            # Middleware(HTTPSRedirectMiddleware)\n        ]\n\n    def custom_format_error(error, debug=False):\n        logging.exception(error)\n\n        return {\"message\": \"An unexpected error occurred, please contact support.\"}\n\n    def start_server(self):\n        self.app = Starlette(\n            routes=self.routes,\n            middleware=self.middleware,\n            on_startup=[self.startup],\n            on_shutdown=[self.shutdown]\n        )\n        return self.app\n\n    async def startup(self):\n        \"\"\"\n        Actions to perform on application startup.\n        \"\"\"\n\n        if self.outer_class:\n            if self.outer_class._at_startup:\n                await self.outer_class._at_startup()\n\n    async def shutdown(self):\n        \"\"\"\n        Actions to perform on application shutdown.\n        \"\"\"\n\n        if self.outer_class:\n            if self.outer_class._at_shutdown:\n                await self.outer_class._at_shutdown()\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.ServerMode.startup","title":"<code>startup()</code>  <code>async</code>","text":"<p>Actions to perform on application startup.</p> Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>async def startup(self):\n    \"\"\"\n    Actions to perform on application startup.\n    \"\"\"\n\n    if self.outer_class:\n        if self.outer_class._at_startup:\n            await self.outer_class._at_startup()\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.ServerMode.shutdown","title":"<code>shutdown()</code>  <code>async</code>","text":"<p>Actions to perform on application shutdown.</p> Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>async def shutdown(self):\n    \"\"\"\n    Actions to perform on application shutdown.\n    \"\"\"\n\n    if self.outer_class:\n        if self.outer_class._at_shutdown:\n            await self.outer_class._at_shutdown()\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.fetch_all","title":"<code>fetch_all(query, values=None)</code>  <code>async</code>","text":"<p>Fetch multiple records from the database.</p> Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>async def fetch_all(self, query, values=None):\n    \"\"\"Fetch multiple records from the database.\"\"\"\n    try:\n        return await self._db_connection_pool.fetch_all(query=query, values=values)\n    except asyncpg.exceptions.PostgresError as e:\n        self.logger.error(\"Database error: %s\", e)\n        raise GraphQLError(\"Database error occurred.\")\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.execute","title":"<code>execute(query, values=None)</code>  <code>async</code>","text":"<p>Execute an INSERT, UPDATE, or DELETE statement.</p> Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>async def execute(self, query, values=None):\n    \"\"\"Execute an INSERT, UPDATE, or DELETE statement.\"\"\"\n    try:\n        return await self._db_connection_pool.execute(query=query, values=values)\n    except asyncpg.exceptions.PostgresError as e:\n        self.logger.error(\"Database execution error: %s\", e)\n        raise GraphQLError(\"Database execution error.\")\n</code></pre>"},{"location":"reference/maoto_agent/#maoto_agent.Maoto.transaction","title":"<code>transaction()</code>  <code>async</code>","text":"<p>Return an async context manager so that <code>async with agent.transaction(): ...</code> works.</p> Source code in <code>maoto_agent/maoto_agent.py</code> <pre><code>@asynccontextmanager\nasync def transaction(self):\n    \"\"\"\n    Return an async context manager so that\n    `async with agent.transaction(): ...` works.\n    \"\"\"\n    async with self._db_connection_pool.transaction():\n        # You can do any setup here if needed\n        yield\n</code></pre>"}]}